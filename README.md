# VOICEâ€‘TOâ€‘SIGN (AVST)

## Bridging Communication Through Inclusive AI
#MaraTechEsprit2026-Teknologia
---

## ðŸ“Œ Project Overview

**AVST is an inclusive AI-powered web application designed to **eliminate communication barriers between hearing people and deaf or hardâ€‘ofâ€‘hearing individuals**.

The platform translates **spoken Tunisian Arabic (and other languages)** into **Tunisian Sign Language (LST)** using a **3D human avatar**, enabling realâ€‘time, accessible, and dignified communicationâ€”especially in **medical, administrative, and emergency contexts**.

This project was developed during the **Maratech Hackathon (6â€“8 February 2026)** in collaboration with the **Association Voix du Sourd de Tunisie (AVST)**, which is committed to maintaining and using the solution beyond the hackathon.

---

## ðŸŽ¯ Problem Statement

Communication between deaf/mute individuals and the hearing population remains a major challenge, particularly when:

* No human interpreter is available
* The situation is urgent (medical emergencies)
* The user is sick, stressed, or physically unable to communicate clearly

Existing solutions are often:

* Limited to static dictionaries
* Not adapted to Tunisian Sign Language
* Videoâ€‘based (nonâ€‘interactive)
* Not accessible to people with additional disabilities

---

## âœ… Our Solution

AVST acts as a **virtual sign language interpreter**, combining:

* **Speech recognition** (Tunisian Arabic)
* **Intelligent phrase matching (ruleâ€‘based + semantic logic)**
* **Real human motion capture**
* **A controllable 3D avatar** that signs accurately in LST

The result is a **fully reusable, scalable, and accessible communication system**, designed for realâ€‘world use.

---

## ðŸ§  Key Features

### ðŸŽ¤ Speechâ€‘toâ€‘Text (Input)

* Realâ€‘time voice capture via microphone
* Tunisian Arabic speech recognition
* Text input fallback for silent or weak users

### ðŸ” Intelligent Mapping Engine

* Ruleâ€‘based dictionary (validated LST phrases)
* Semantic matching for STT errors and variants
* Phraseâ€‘level and wordâ€‘level fallback logic

### ðŸ§â€â™‚ï¸ 3D Avatar Sign Language Output

* Photorealistic humanoid avatar
* Driven by **real human motion** using AI motion capture
* Sequential animation playback (sign chaining)
* Accurate arm, body, and hand articulation

### â™¿ Accessibilityâ€‘First Design

* Highâ€‘contrast, colorâ€‘blind safe UI (blueâ€‘based)
* Large text & simplified language modes
* Lowâ€‘energy / fatigueâ€‘aware mode
* Touchâ€‘based communication (icons instead of voice)

### ðŸš‘ Health & Emergency Support

* Emergency phrase mode (pain, breathing, allergies, chronic illness)
* Symptomâ€‘toâ€‘communication mapper
* Caregiver / doctor dualâ€‘view interface

### ðŸŒ Inclusive by Design

* Multiâ€‘language input (Tunisian Arabic, French, English, Spanish)
* Output always in Tunisian Sign Language
* Designed for hospitals, public services, and daily life

---

## ðŸ—ï¸ Technical Architecture

### Frontend

* **React.js**
* **Node.js**

### 3D & Animation Pipeline

* Humanoid avatar (GLB / GLTF)
* Motion capture from real human videos using **DeepMotion**
* Animation cleanup and retargeting via **SketchFab**
* Multiple named animation clips (HELLO, THANKS, HELP, etc.)

### AI & Logic

* Speechâ€‘toâ€‘Text engine (Tunisian dialect)
* Deterministic animation orchestration (playlist model)

### Assets

* LST dictionary and video references provided & validated with AVST mentors
* Animations mapped to standardized sign IDs

---

## ðŸ”„ System Workflow

1. User speaks or types
2. Speech is transcribed into text
3. Text is normalized and matched against LST dictionary
4. Matching engine returns a sequence of sign IDs
5. 3D avatar plays the corresponding animations in order
6. Optional subtitles / voice output displayed

---

## ðŸ“¦ Deliverables (Hackathon Scope)

### MVP (Achieved)

* Functional Voice â†’ Avatar pipeline
* Basic LST sign set
* Realâ€‘time interaction

### Ideal Target

* Full sentence signing
* Smooth animation transitions
* Productionâ€‘ready UI

---

## ðŸ¤ Collaboration with AVST

The Association Voix du Sourd de Tunisie provided:

* Linguistic expertise in Tunisian Sign Language
* Validation of gestures and sign accuracy
* Realâ€‘world usage insights

AVST has formally committed to:

* Using the solution after the hackathon
* Participating in future improvements

---

## ðŸ† Innovation Highlights

* **Not a video avatar**: fully controllable 3D human
* Real human motion transfer, not synthetic gestures
* Designed for **medical and vulnerable contexts**
* Accessibility as a default, not an addâ€‘on

> â€œWe donâ€™t generate videos of humans â€” we generate humans that can communicate.â€

---

## ðŸš€ Roadmap

### Shortâ€‘Term

* Expand LST vocabulary
* Improve finger precision
* Add offline emergency phrases

### Midâ€‘Term

* Bidirectional mode (Sign â†’ Text)
* Integration with hospitals & public services
* User profiles (medical data)

### Longâ€‘Term

* MetaHumanâ€‘level realism
* AIâ€‘assisted sign generation
* National deployment with AVST

---

## ðŸ“œ License & Ethics

This project is developed with:

* Full respect of deaf culture and linguistic integrity
* Ethical AI principles
* Nonâ€‘profit social impact alignment

---

## ðŸ‘¥ Team & Event

* **Hackathon**: Maratech Hackathon 2026
* **Team Name** :Teknologia
* **Duration**: 42 hours
* **Focus**: Accessibility, Health, Social Inclusion

---

## ðŸ“ž Contact

For partnerships, deployment, or further development:

**Association Voix du Sourd de Tunisie (AVST)**
Project Reference: *Voiceâ€‘toâ€‘Sign*

---

> Accessibility is not a feature. It is the foundation.
